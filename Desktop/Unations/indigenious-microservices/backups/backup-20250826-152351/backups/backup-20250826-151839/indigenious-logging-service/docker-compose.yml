version: '3.8'

services:
  logging-service:
    build: .
    ports:
      - "3043:3043"
    environment:
      - NODE_ENV=production
      - PORT=3043
      - DATABASE_URL=postgresql://logging_user:logging_pass@logging-db:5432/indigenous_logging_db
      - REDIS_URL=redis://logging-redis:6379
      - REDIS_HOST=logging-redis
      - REDIS_PORT=6379
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - KAFKA_BROKERS=kafka:9092
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672
      - LOG_LEVEL=info
      - JWT_SECRET=${JWT_SECRET}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
    depends_on:
      - logging-db
      - logging-redis
      - elasticsearch
      - kibana
      - kafka
      - zookeeper
      - fluentd
    networks:
      - logging-network
      - microservices-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3043/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    volumes:
      - ./logs:/app/logs
      - ./archives:/app/archives

  logging-db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=indigenous_logging_db
      - POSTGRES_USER=logging_user
      - POSTGRES_PASSWORD=logging_pass
    volumes:
      - logging-db-data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5449:5432"
    networks:
      - logging-network
    restart: unless-stopped

  logging-redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 1024mb --maxmemory-policy allkeys-lru
    ports:
      - "6399:6379"
    volumes:
      - logging-redis-data:/data
    networks:
      - logging-network
    restart: unless-stopped

  elasticsearch:
    image: elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - cluster.name=indigenous-logs-cluster
      - node.name=es01
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - logging-network
    restart: unless-stopped
    ulimits:
      memlock:
        soft: -1
        hard: -1

  kibana:
    image: kibana:8.11.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_NAME=kibana
      - SERVER_HOST=0.0.0.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - logging-network
    restart: unless-stopped

  logstash:
    image: logstash:8.11.0
    environment:
      - "LS_JAVA_OPTS=-Xmx512m -Xms512m"
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
    ports:
      - "5044:5044"
      - "9600:9600"
    depends_on:
      - elasticsearch
    networks:
      - logging-network
    restart: unless-stopped

  fluentd:
    image: fluent/fluentd:latest
    volumes:
      - ./fluentd/conf:/fluentd/etc
      - ./logs:/var/log
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    depends_on:
      - elasticsearch
    networks:
      - logging-network
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_LOG_RETENTION_HOURS=168
      - KAFKA_LOG_RETENTION_BYTES=1073741824
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - logging-network
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_LOG4J_ROOT_LOGLEVEL=WARN
      - ZOOKEEPER_LOG4J_PROP=WARN,CONSOLE
    ports:
      - "2181:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - logging-network
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:3-management-alpine
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=admin123
      - RABBITMQ_DEFAULT_VHOST=/
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    networks:
      - logging-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-elasticsearch-datasource
    ports:
      - "3044:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - elasticsearch
    networks:
      - logging-network
    restart: unless-stopped

  jaeger:
    image: jaegertracing/all-in-one:latest
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - ES_TAGS_AS_FIELDS_ALL=true
    ports:
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
    depends_on:
      - elasticsearch
    networks:
      - logging-network
    restart: unless-stopped

  filebeat:
    image: elastic/filebeat:8.11.0
    user: root
    environment:
      - output.elasticsearch.hosts=["elasticsearch:9200"]
      - setup.kibana.host=kibana:5601
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./logs:/var/log/app:ro
    depends_on:
      - elasticsearch
      - kibana
    networks:
      - logging-network
    restart: unless-stopped

volumes:
  logging-db-data:
    driver: local
  logging-redis-data:
    driver: local
  elasticsearch-data:
    driver: local
  kafka-data:
    driver: local
  zookeeper-data:
    driver: local
  zookeeper-logs:
    driver: local
  rabbitmq-data:
    driver: local
  grafana-data:
    driver: local

networks:
  logging-network:
    driver: bridge
  microservices-network:
    external: true